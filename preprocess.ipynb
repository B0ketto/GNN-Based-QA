{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686e317-5e60-485b-8c55-2b8ea3c8369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6dde47-8a26-4482-9dcc-8574203043d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.11)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (6.1.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2019.11.28)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25, torch_geometric\n",
      "Successfully installed rank_bm25-0.2.2 torch_geometric-2.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5aa1ba1-f218-47f0-9f15-d568f9738fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GATConv, global_max_pool\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c4d884-82bd-481f-9eb8-7fe18db5b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbfd8a-32c2-4940-931e-e788cf5ad301",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ede81b-28ac-49da-bc5a-417b228d8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_passages(instance):\n",
    "    passages = []\n",
    "    for entity, facts in instance['context']:\n",
    "        for idx, fact in enumerate(facts):\n",
    "            passages.append({\n",
    "                'text': fact,\n",
    "                'entity': entity,\n",
    "                'position': idx,\n",
    "                'is_supporting': (entity, idx) in instance['supporting_facts']\n",
    "            })\n",
    "    return passages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17706fc8-2855-44e4-96dc-d465f42b2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitProcessor:\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer(max_features=5000)\n",
    "        self.embedder = SentenceTransformer('all-mpnet-base-v2')\n",
    "        \n",
    "    def fit(self, train_instances):\n",
    "        \"\"\"Train on training data only\"\"\"\n",
    "        train_texts = [p['text'] for inst in train_instances \n",
    "                      for p in extract_passages(inst)]\n",
    "        self.tfidf.fit(train_texts)\n",
    "        # Warmup embedding model\n",
    "        self.embedder.encode(train_texts[:1000]) \n",
    "\n",
    "    def process(self, instances):\n",
    "        \"\"\"Process any split\"\"\"\n",
    "        processed = []\n",
    "        for inst in instances:\n",
    "            passages = extract_passages(inst)\n",
    "            # Generate features\n",
    "            tfidf = self.tfidf.transform([p['text'] for p in passages])\n",
    "            embeds = self.embedder.encode([p['text'] for p in passages])\n",
    "            # Build graph\n",
    "            graph = build_graph(passages, tfidf, embeds, inst['evidences'])\n",
    "            processed.append(graph)\n",
    "        return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectiveSampler:\n",
    "    def __init__(self, num_neighbors=10, distance_metric='cosine'):\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def __call__(self, x, edge_index=None):\n",
    "        num_nodes = x.size(0)\n",
    "\n",
    "        # print(f\"\\n[SelectiveSampler] Number of nodes: {num_nodes}\")\n",
    "\n",
    "        if num_nodes < 2:\n",
    "            # print(\"[SelectiveSampler] Too few nodes, returning empty edge set.\")\n",
    "            return torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        num_neighbors = min(self.num_neighbors + 1, num_nodes)  # +1 to include self (we'll skip later)\n",
    "        # print(f\"[SelectiveSampler] num_neighbors used (including self): {num_neighbors}\")\n",
    "\n",
    "        if self.distance_metric == 'cosine':\n",
    "            x_norm = torch.nn.functional.normalize(x, p=2, dim=1)\n",
    "            similarity = x_norm @ x_norm.T\n",
    "            _, topk = torch.topk(similarity, num_neighbors, dim=-1)\n",
    "        elif self.distance_metric == 'euclidean':\n",
    "            dists = torch.cdist(x, x, p=2)\n",
    "            _, topk = torch.topk(-dists, num_neighbors, dim=-1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "\n",
    "        # print(f\"[SelectiveSampler] topk indices per node (including self):\")\n",
    "        # for i in range(num_nodes):\n",
    "        #     print(f\"  Node {i}: {topk[i].tolist()}\")\n",
    "\n",
    "        sampled_edges = []\n",
    "        for i in range(num_nodes):\n",
    "            for j in topk[i]:\n",
    "                if i != j:\n",
    "                    sampled_edges.append((i, j.item()))\n",
    "\n",
    "        # if not sampled_edges:\n",
    "            # print(\"[SelectiveSampler] No valid edges formed (only self-loops found).\")\n",
    "\n",
    "        edge_tensor = torch.tensor(sampled_edges, dtype=torch.long).t().contiguous()\n",
    "        # print(f\"[SelectiveSampler] Final sampled edge_index shape: {edge_tensor.shape}\")\n",
    "\n",
    "        return edge_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9659de-13a3-455b-9d31-55479ae9dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(passages, tfidf, embeds, evidences):\n",
    "    edge_index = []\n",
    "    \n",
    "    # 1. Sequential connections\n",
    "    entity_pos = defaultdict(list)\n",
    "    for i, p in enumerate(passages):\n",
    "        entity_pos[p['entity']].append(i)\n",
    "    for ents in entity_pos.values():\n",
    "        edge_index += [(ents[i], ents[i+1]) for i in range(len(ents)-1)]\n",
    "    \n",
    "    # 2. Semantic similarity (cosine > 0.7)\n",
    "    cos_sim = cosine_similarity(embeds)\n",
    "    rows, cols = np.where(cos_sim > 0.7)\n",
    "    edge_index += list(zip(rows, cols))\n",
    "    \n",
    "    # 3. Keyword overlap (TF-IDF > 0.25)\n",
    "    tfidf_sim = (tfidf * tfidf.T).toarray()\n",
    "    rows, cols = np.where(tfidf_sim > 0.25)\n",
    "    edge_index += list(zip(rows, cols))\n",
    "    \n",
    "    # 4. Evidence links\n",
    "    entity_map = {p['entity']:i for i,p in enumerate(passages)}\n",
    "    for subj, _, obj in evidences:\n",
    "        if subj in entity_map and obj in entity_map:\n",
    "            edge_index.append((entity_map[subj], entity_map[obj]))\n",
    "    \n",
    "    # Convert to PyG Data\n",
    "    return Data(\n",
    "        x=torch.tensor(embeds, dtype=torch.float32),\n",
    "        edge_index=torch.tensor(edge_index).t().contiguous(),\n",
    "        y=torch.tensor([p['is_supporting'] for p in passages], dtype=torch.float)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243aced-22a5-4c49-bd49-9d148955253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SplitProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc7b61-cea1-4f8e-99ee-01077b8691a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with open('data/train.json') as f:\n",
    "    train = json.load(f)\n",
    "processor.fit(train) \n",
    "\n",
    "train_data = processor.process(train)\n",
    "val_data = processor.process(json.load(open('data/dev.json')))\n",
    "torch.save(val_data, f'data/dev.pt')\n",
    "test_data = processor.process(json.load(open('data/test.json')))\n",
    "torch.save(train_data, f'data/train.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
